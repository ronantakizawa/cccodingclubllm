{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This LLM Finetuning tutorial is based on this:\n",
        "https://colab.research.google.com/drive/16e_HJwCHNsATFVtljZTMg0JydrHAhO8A#scrollTo=45DJZ7hHaBx0"
      ],
      "metadata": {
        "id": "MlIvzuf6CF12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data generation step"
      ],
      "metadata": {
        "id": "Way3_PuPpIuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your prompt here. Make it as descriptive as possible!\n",
        "\n",
        "Then, choose the temperature (between 0 and 1) to use when generating data. Lower values are great for precise tasks, like writing code, whereas larger values are better for creative tasks, like writing stories.\n",
        "\n",
        "Finally, choose how many examples you want to generate. The more you generate, a) the longer it takes and b) the more expensive data generation will be. But generally, more examples will lead to a higher-quality model. 100 is usually the minimum to start."
      ],
      "metadata": {
        "id": "lY-3DvlIpVSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A model that gives me responses to my prompts both in english and spanish every time.\"\n",
        "temperature = .4\n",
        "number_of_examples = 100"
      ],
      "metadata": {
        "id": "R7WKZyxtpUPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this to generate the dataset."
      ],
      "metadata": {
        "id": "1snNou5PrIci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai tenacity"
      ],
      "metadata": {
        "id": "zuL2UaqlsmBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f86a3945-8b25-43d5-ec54-4242651adfea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import random\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "openai.api_key = \"API-KEY\"\n",
        "\n",
        "N_RETRIES = 3\n",
        "\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def generate_example(prompt, prev_examples, temperature=.5):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\n$prompt_goes_here\\n-----------\\n\\nresponse\\n-----------\\n$response_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\\n\\nHere is the type of model we want to train:\\n`{prompt}`\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if len(prev_examples) > 0:\n",
        "        if len(prev_examples) > 8:\n",
        "            prev_examples = random.sample(prev_examples, 8)\n",
        "        for example in prev_examples:\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": example\n",
        "            })\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Generate examples\n",
        "prev_examples = []\n",
        "for i in range(number_of_examples):\n",
        "    print(f'Generating example {i}')\n",
        "    example = generate_example(prompt, prev_examples, temperature)\n",
        "    prev_examples.append(example)\n",
        "\n",
        "print(prev_examples)"
      ],
      "metadata": {
        "id": "Rdsd82ngpHCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec498dda-8cda-42c5-f4ad-1001f0b029f7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating example 0\n",
            "Generating example 1\n",
            "Generating example 2\n",
            "Generating example 3\n",
            "Generating example 4\n",
            "Generating example 5\n",
            "Generating example 6\n",
            "Generating example 7\n",
            "Generating example 8\n",
            "Generating example 9\n",
            "Generating example 10\n",
            "Generating example 11\n",
            "Generating example 12\n",
            "Generating example 13\n",
            "Generating example 14\n",
            "Generating example 15\n",
            "Generating example 16\n",
            "Generating example 17\n",
            "Generating example 18\n",
            "Generating example 19\n",
            "Generating example 20\n",
            "Generating example 21\n",
            "Generating example 22\n",
            "Generating example 23\n",
            "Generating example 24\n",
            "Generating example 25\n",
            "Generating example 26\n",
            "Generating example 27\n",
            "Generating example 28\n",
            "Generating example 29\n",
            "Generating example 30\n",
            "Generating example 31\n",
            "Generating example 32\n",
            "Generating example 33\n",
            "Generating example 34\n",
            "Generating example 35\n",
            "Generating example 36\n",
            "Generating example 37\n",
            "Generating example 38\n",
            "Generating example 39\n",
            "Generating example 40\n",
            "Generating example 41\n",
            "Generating example 42\n",
            "Generating example 43\n",
            "Generating example 44\n",
            "Generating example 45\n",
            "Generating example 46\n",
            "Generating example 47\n",
            "Generating example 48\n",
            "Generating example 49\n",
            "['prompt\\n-----------\\nWhat is the weather like today?\\n-----------\\n\\nresponse\\n-----------\\nThe weather today is sunny and warm. / El clima hoy es soleado y cálido.\\n-----------', \"prompt\\n-----------\\nCan you tell me a joke?\\n-----------\\n\\nresponse\\n-----------\\nSure, here is a joke for you: Why don't scientists trust atoms? Because they make up everything! / Claro, aquí tienes un chiste: ¿Por qué los científicos no confían en los átomos? ¡Porque lo inventan todo!\\n-----------\", \"prompt\\n-----------\\nWhat's the recipe for a chocolate cake?\\n-----------\\n\\nresponse\\n-----------\\nFor a basic chocolate cake, you'll need: 200g all-purpose flour, 200g sugar, 100g unsweetened cocoa powder, 1.5 tsp baking powder, 1.5 tsp baking soda, 1 tsp salt, 2 eggs, 1 cup milk, 1/2 cup vegetable oil, 2 tsp vanilla extract, and 1 cup boiling water. / Para un pastel de chocolate básico, necesitarás: 200g de harina común, 200g de azúcar, 100g de cacao en polvo sin azúcar, 1.5 cucharaditas de polvo de hornear, 1.5 cucharaditas de bicarbonato de sodio, 1 cucharadita de sal, 2 huevos, 1 taza de leche, 1/2 taza de aceite vegetal, 2 cucharaditas de extracto de vainilla, y 1 taza de agua hirviendo.\\n-----------\", 'prompt\\n-----------\\nWhat are the main tourist attractions in Paris?\\n-----------\\n\\nresponse\\n-----------\\nThe main tourist attractions in Paris include the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, Montmartre, and the Palace of Versailles. / Las principales atracciones turísticas en París incluyen la Torre Eiffel, el Museo del Louvre, la Catedral de Notre-Dame, Montmartre y el Palacio de Versalles.\\n-----------', \"prompt\\n-----------\\nHow can I get to the nearest hospital from here?\\n-----------\\n\\nresponse\\n-----------\\nI'm sorry, I can't provide real-time directions as I am a text-based model. However, you can use a GPS or online map service for directions. / Lo siento, no puedo proporcionar direcciones en tiempo real ya que soy un modelo basado en texto. Sin embargo, puedes usar un GPS o un servicio de mapas en línea para obtener direcciones.\\n-----------\", \"prompt\\n-----------\\nWhat are the benefits of regular exercise?\\n-----------\\n\\nresponse\\n-----------\\nRegular exercise can help prevent chronic diseases, improve your mood, boost your energy levels, promote better sleep, and it's also a great way to relax and reduce stress. / El ejercicio regular puede ayudar a prevenir enfermedades crónicas, mejorar tu estado de ánimo, aumentar tus niveles de energía, promover un mejor sueño, y también es una excelente manera de relajarse y reducir el estrés.\\n-----------\", 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat is the best way to learn a new language?\\n-----------\\n\\nresponse\\n-----------\\nThe best way to learn a new language is through immersion, practicing speaking and listening regularly, using language learning apps, and taking language classes if possible. / La mejor manera de aprender un nuevo idioma es a través de la inmersión, practicando hablar y escuchar regularmente, utilizando aplicaciones de aprendizaje de idiomas y tomando clases de idiomas si es posible.\\n-----------', 'prompt\\n-----------\\nWhat are the symptoms of the common cold?\\n-----------\\n\\nresponse\\n-----------\\nThe symptoms of the common cold can include a runny or stuffy nose, sore throat, cough, congestion, slight body aches, mild headache, sneezing, low-grade fever, and malaise. / Los síntomas del resfriado común pueden incluir una nariz que moquea o está congestionada, dolor de garganta, tos, congestión, dolores corporales leves, dolor de cabeza leve, estornudos, fiebre baja y malestar.\\n-----------', 'prompt\\n-----------\\nWhat are the ingredients for a Margherita pizza?\\n-----------\\n\\nresponse\\n-----------\\nThe ingredients for a Margherita pizza are: pizza dough, tomato sauce, fresh mozzarella cheese, fresh basil leaves, olive oil, and a pinch of salt. / Los ingredientes para una pizza Margherita son: masa de pizza, salsa de tomate, queso mozzarella fresco, hojas de albahaca frescas, aceite de oliva y una pizca de sal.\\n-----------', 'prompt\\n-----------\\nWhat is the capital of Spain?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Spain is Madrid. / La capital de España es Madrid.\\n-----------', 'prompt\\n-----------\\nWho wrote the novel \"To Kill a Mockingbird\"?\\n-----------\\n\\nresponse\\n-----------\\nThe novel \"To Kill a Mockingbird\" was written by Harper Lee. / La novela \"Matar a un ruiseñor\" fue escrita por Harper Lee.\\n-----------', 'prompt\\n-----------\\nHow do I reset my router?\\n-----------\\n\\nresponse\\n-----------\\nTo reset your router, locate the reset button (usually a small hole), use a paperclip to press and hold the button for about 10 seconds. The router will then restart. / Para reiniciar tu router, localiza el botón de reset (generalmente un pequeño agujero), usa un clip de papel para presionar y mantener el botón durante unos 10 segundos. Luego el router se reiniciará.\\n-----------', \"prompt\\n-----------\\nWhat is the weather like today?\\n-----------\\n\\nresponse\\n-----------\\nI'm sorry, I can't provide real-time weather information as I am a text-based model. I recommend checking a reliable weather forecasting website or app. / Lo siento, no puedo proporcionar información meteorológica en tiempo real ya que soy un modelo basado en texto. Te recomiendo consultar un sitio web o aplicación de pronóstico del tiempo confiable.\\n-----------\", 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat are the benefits of regular exercise?\\n-----------\\n\\nresponse\\n-----------\\nRegular exercise can help prevent chronic diseases, improve mood and mental health, aid in weight management, and boost overall energy levels. / El ejercicio regular puede ayudar a prevenir enfermedades crónicas, mejorar el estado de ánimo y la salud mental, ayudar en el control del peso y aumentar los niveles generales de energía.\\n-----------', 'prompt\\n-----------\\nCan you tell me a fun fact about cats?\\n-----------\\n\\nresponse\\n-----------\\nSure, did you know that cats can make around 100 different sounds? Dogs, on the other hand, can make about 10. / Claro, ¿sabías que los gatos pueden hacer alrededor de 100 sonidos diferentes? Los perros, por otro lado, pueden hacer alrededor de 10.\\n-----------', 'prompt\\n-----------\\nWhat is the meaning of life?\\n-----------\\n\\nresponse\\n-----------\\nThe meaning of life varies from person to person, culture to culture, and belief to belief. Some people find meaning in personal growth, relationships, love, and the pursuit of knowledge. / El significado de la vida varía de persona a persona, de cultura a cultura y de creencia a creencia. Algunas personas encuentran significado en el crecimiento personal, las relaciones, el amor y la búsqueda del conocimiento.\\n-----------', 'prompt\\n-----------\\nWhat are the symptoms of the common cold?\\n-----------\\n\\nresponse\\n-----------\\nThe symptoms of the common cold can include a runny or stuffy nose, sore throat, cough, congestion, slight body aches, mild headache, sneezing, low-grade fever, and mild fatigue. / Los síntomas del resfriado común pueden incluir una nariz que moquea o está congestionada, dolor de garganta, tos, congestión, leves dolores corporales, dolor de cabeza leve, estornudos, fiebre baja y fatiga leve.\\n-----------', 'prompt\\n-----------\\nWhat are the symptoms of the common cold?\\n-----------\\n\\nresponse\\n-----------\\nThe symptoms of the common cold can include: a runny or stuffy nose, sore throat, cough, congestion, slight body aches, mild headache, sneezing, low-grade fever, and malaise. / Los síntomas del resfriado común pueden incluir: nariz congestionada o que gotea, dolor de garganta, tos, congestión, dolores corporales leves, dolor de cabeza leve, estornudos, fiebre baja y malestar general.\\n-----------', 'prompt\\n-----------\\nCan you tell me a fun fact about cats?\\n-----------\\n\\nresponse\\n-----------\\nSure, did you know that cats sleep for 13 to 14 hours a day? / Claro, ¿sabías que los gatos duermen de 13 a 14 horas al día?\\n-----------', 'prompt\\n-----------\\nWhat is the Pythagorean theorem?\\n-----------\\n\\nresponse\\n-----------\\nThe Pythagorean theorem states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. This can be written as: a² + b² = c². / El teorema de Pitágoras establece que en un triángulo rectángulo, el cuadrado de la longitud de la hipotenusa (el lado opuesto al ángulo recto) es igual a la suma de los cuadrados de las longitudes de los otros dos lados. Esto se puede escribir como: a² + b² = c².\\n-----------', 'prompt\\n-----------\\nWhat are the ingredients in a Margherita pizza?\\n-----------\\n\\nresponse\\n-----------\\nA Margherita pizza typically includes: pizza dough, tomato sauce, fresh mozzarella cheese, fresh basil, and olive oil. / Una pizza Margherita típicamente incluye: masa de pizza, salsa de tomate, queso mozzarella fresco, albahaca fresca y aceite de oliva.\\n-----------', 'prompt\\n-----------\\nWhat is the distance between Earth and Mars?\\n-----------\\n\\nresponse\\n-----------\\nThe average distance from Mars to Earth is about 225 million kilometers. However, this distance varies as both Earth and Mars follow elliptical orbits. / La distancia promedio de Marte a la Tierra es de aproximadamente 225 millones de kilómetros. Sin embargo, esta distancia varía ya que tanto la Tierra como Marte siguen órbitas elípticas.\\n-----------', 'prompt\\n-----------\\nWhat is the recipe for a chocolate cake?\\n-----------\\n\\nresponse\\n-----------\\nA basic chocolate cake recipe includes: 1 cup unsweetened cocoa powder, 1.5 cups all-purpose flour, 2 cups sugar, 1.5 tsp baking powder, 1.5 tsp baking soda, 1 tsp salt, 2 eggs, 1 cup milk, 0.5 cup vegetable oil, 2 tsp vanilla extract, and 1 cup boiling water. / Una receta básica de pastel de chocolate incluye: 1 taza de cacao en polvo sin azúcar, 1.5 tazas de harina común, 2 tazas de azúcar, 1.5 cucharaditas de polvo de hornear, 1.5 cucharaditas de bicarbonato de sodio, 1 cucharadita de sal, 2 huevos, 1 taza de leche, 0.5 taza de aceite vegetal, 2 cucharaditas de extracto de vainilla y 1 taza de agua hirviendo.\\n-----------', 'prompt\\n-----------\\nWhat is the tallest mountain in the world?\\n-----------\\n\\nresponse\\n-----------\\nThe tallest mountain in the world is Mount Everest, which is approximately 8,848 meters above sea level. / La montaña más alta del mundo es el Monte Everest, que mide aproximadamente 8,848 metros sobre el nivel del mar.\\n-----------', 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat is the tallest mountain in the world?\\n-----------\\n\\nresponse\\n-----------\\nThe tallest mountain in the world is Mount Everest, which stands at approximately 8,848 meters above sea level. / La montaña más alta del mundo es el Monte Everest, que se eleva a aproximadamente 8,848 metros sobre el nivel del mar.\\n-----------', 'prompt\\n-----------\\nWhat are some good books to read?\\n-----------\\n\\nresponse\\n-----------\\nSome good books to read are \"To Kill a Mockingbird\" by Harper Lee, \"1984\" by George Orwell, and \"Pride and Prejudice\" by Jane Austen. / Algunos buenos libros para leer son \"Matar a un ruiseñor\" de Harper Lee, \"1984\" de George Orwell y \"Orgullo y prejuicio\" de Jane Austen.\\n-----------', 'prompt\\n-----------\\nWhat is the distance between the Earth and the Moon?\\n-----------\\n\\nresponse\\n-----------\\nThe average distance from the Moon to the Earth is about 238,855 miles (384,400 kilometers). / La distancia promedio de la Luna a la Tierra es de aproximadamente 238,855 millas (384,400 kilómetros).\\n-----------', 'prompt\\n-----------\\nWhat is the recipe for a chocolate cake?\\n-----------\\n\\nresponse\\n-----------\\nA basic recipe for a chocolate cake includes: 1 cup unsweetened cocoa powder, 1 1/2 cups all-purpose flour, 2 cups sugar, 1 1/2 teaspoons baking powder, 1 1/2 teaspoons baking soda, 1 teaspoon salt, 2 eggs, 1 cup whole milk, 1/2 cup vegetable oil, 2 teaspoons vanilla extract, and 1 cup boiling water. / Una receta básica para un pastel de chocolate incluye: 1 taza de cacao en polvo sin azúcar, 1 1/2 tazas de harina de trigo, 2 tazas de azúcar, 1 1/2 cucharaditas de polvo de hornear, 1 1/2 cucharaditas de bicarbonato de sodio, 1 cucharadita de sal, 2 huevos, 1 taza de leche entera, 1/2 taza de aceite vegetal, 2 cucharaditas de extracto de vainilla y 1 taza de agua hirviendo.\\n-----------', 'prompt\\n-----------\\nWhat is the fastest animal on land?\\n-----------\\n\\nresponse\\n-----------\\nThe fastest animal on land is the cheetah, which can reach speeds up to 60-70 miles per hour. / El animal más rápido en tierra es el guepardo, que puede alcanzar velocidades de hasta 60-70 millas por hora.\\n-----------', 'prompt\\n-----------\\nWhat is the first law of thermodynamics?\\n-----------\\n\\nresponse\\n-----------\\nThe first law of thermodynamics, also known as the Law of Energy Conservation, states that energy cannot be created or destroyed in an isolated system. / La primera ley de la termodinámica, también conocida como la Ley de Conservación de Energía, establece que la energía no puede ser creada ni destruida en un sistema aislado.\\n-----------', 'prompt\\n-----------\\nWhat are the benefits of regular exercise?\\n-----------\\n\\nresponse\\n-----------\\nRegular exercise can help prevent chronic diseases, improve mood and mental health, strengthen your muscles and bones, improve sleep, and increase your lifespan. / El ejercicio regular puede ayudar a prevenir enfermedades crónicas, mejorar el estado de ánimo y la salud mental, fortalecer los músculos y huesos, mejorar el sueño y aumentar la esperanza de vida.\\n-----------', 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat are the symptoms of the common cold?\\n-----------\\n\\nresponse\\n-----------\\nCommon cold symptoms include runny or stuffy nose, sore throat, cough, congestion, slight body aches or a mild headache, sneezing, low-grade fever, and mild fatigue. / Los síntomas del resfriado común incluyen nariz congestionada o secreción nasal, dolor de garganta, tos, congestión, leves dolores corporales o un leve dolor de cabeza, estornudos, fiebre baja y fatiga leve.\\n-----------', 'prompt\\n-----------\\nWhat are the benefits of regular exercise?\\n-----------\\n\\nresponse\\n-----------\\nRegular exercise helps control weight, reduces the risk of heart diseases, helps your body manage blood sugar and insulin levels, improves mental health and mood, and promotes better sleep among other benefits. / El ejercicio regular ayuda a controlar el peso, reduce el riesgo de enfermedades del corazón, ayuda a su cuerpo a manejar los niveles de azúcar en la sangre y de insulina, mejora la salud mental y el estado de ánimo, y promueve un mejor sueño entre otros beneficios.\\n-----------', 'prompt\\n-----------\\nWhat is the Pythagorean theorem?\\n-----------\\n\\nresponse\\n-----------\\nThe Pythagorean theorem states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. This can be written as: a² + b² = c². / El teorema de Pitágoras establece que en un triángulo rectángulo, el cuadrado de la longitud de la hipotenusa (el lado opuesto al ángulo recto) es igual a la suma de los cuadrados de las longitudes de los otros dos lados. Esto se puede escribir como: a² + b² = c².\\n-----------', 'prompt\\n-----------\\nWhat are the benefits of drinking water?\\n-----------\\n\\nresponse\\n-----------\\nDrinking water helps maintain the balance of body fluids, aids digestion, regulates body temperature, helps transport nutrients, and keeps skin looking good. / Beber agua ayuda a mantener el equilibrio de los líquidos corporales, ayuda a la digestión, regula la temperatura corporal, ayuda a transportar nutrientes y mantiene la piel en buen estado.\\n-----------', 'prompt\\n-----------\\nHow do I take care of a bonsai tree?\\n-----------\\n\\nresponse\\n-----------\\nTaking care of a bonsai tree involves proper watering, appropriate fertilization, ensuring the tree gets enough light, maintaining the right temperature and humidity, and regular pruning. / Cuidar un árbol bonsái implica un riego adecuado, fertilización apropiada, asegurarse de que el árbol reciba suficiente luz, mantener la temperatura y humedad correctas, y poda regular.\\n-----------', 'prompt\\n-----------\\nWhat is photosynthesis?\\n-----------\\n\\nresponse\\n-----------\\nPhotosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments. In this process, carbon dioxide and water are converted into glucose and oxygen. / La fotosíntesis es el proceso mediante el cual las plantas verdes y algunos otros organismos utilizan la luz solar para sintetizar alimentos con la ayuda de pigmentos de clorofila. En este proceso, el dióxido de carbono y el agua se convierten en glucosa y oxígeno.\\n-----------', 'prompt\\n-----------\\nWhat is the capital of Australia?\\n-----------\\n\\nresponse\\n-----------\\nThe capital of Australia is Canberra. / La capital de Australia es Canberra.\\n-----------', 'prompt\\n-----------\\nWhat is the Mona Lisa?\\n-----------\\n\\nresponse\\n-----------\\nThe Mona Lisa is a half-length portrait painting by the Italian artist Leonardo da Vinci. It is considered an iconic masterpiece of the Italian Renaissance and is housed in the Louvre Museum in Paris. / La Mona Lisa es una pintura de medio cuerpo del artista italiano Leonardo da Vinci. Se considera una obra maestra icónica del Renacimiento italiano y se encuentra en el Museo del Louvre en París.\\n-----------', \"prompt\\n-----------\\nWhat is photosynthesis?\\n-----------\\n\\nresponse\\n-----------\\nPhotosynthesis is a process used by plants and other organisms to convert light energy, usually from the Sun, into chemical energy that can be later released to fuel the organisms' activities. / La fotosíntesis es un proceso utilizado por las plantas y otros organismos para convertir la energía luminosa, generalmente del Sol, en energía química que luego puede liberarse para alimentar las actividades de los organismos.\\n-----------\", \"prompt\\n-----------\\nWhat is the weather like today?\\n-----------\\n\\nresponse\\n-----------\\nI'm sorry, I can't provide real-time weather updates as I am a text-based model. Please check a reliable weather forecasting site or app for current conditions. / Lo siento, no puedo proporcionar actualizaciones del tiempo en tiempo real ya que soy un modelo basado en texto. Por favor, consulta un sitio o aplicación de pronóstico del tiempo confiable para conocer las condiciones actuales.\\n-----------\", 'prompt\\n-----------\\nWhat is photosynthesis?\\n-----------\\n\\nresponse\\n-----------\\nPhotosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll pigments. In the process, they convert carbon dioxide and water into sugars and release oxygen as a by-product. / La fotosíntesis es el proceso por el cual las plantas verdes y algunos otros organismos utilizan la luz solar para sintetizar alimentos con la ayuda de pigmentos de clorofila. En el proceso, convierten el dióxido de carbono y el agua en azúcares y liberan oxígeno como subproducto.\\n-----------', 'prompt\\n-----------\\nWhat are some good books to read?\\n-----------\\n\\nresponse\\n-----------\\nSome good books to read are \"To Kill a Mockingbird\" by Harper Lee, \"1984\" by George Orwell, and \"Pride and Prejudice\" by Jane Austen. / Algunos buenos libros para leer son \"Matar a un ruiseñor\" de Harper Lee, \"1984\" de George Orwell y \"Orgullo y prejuicio\" de Jane Austen.\\n-----------', 'prompt\\n-----------\\nWhat are the benefits of regular exercise?\\n-----------\\n\\nresponse\\n-----------\\nRegular exercise can have a lot of benefits such as improving your mood, boosting your energy, promoting better sleep, combating health conditions and diseases, and helping control weight. / El ejercicio regular puede tener muchos beneficios, como mejorar tu estado de ánimo, aumentar tu energía, promover un mejor sueño, combatir condiciones y enfermedades de salud, y ayudar a controlar el peso.\\n-----------', 'prompt\\n-----------\\nWhat is the tallest mountain in the world?\\n-----------\\n\\nresponse\\n-----------\\nThe tallest mountain in the world is Mount Everest, which is located in the Himalayas and has a height of approximately 8,848 meters above sea level. / La montaña más alta del mundo es el Monte Everest, que se encuentra en el Himalaya y tiene una altura de aproximadamente 8,848 metros sobre el nivel del mar.\\n-----------']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to generate a system message."
      ],
      "metadata": {
        "id": "KC6iJzXjugJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_system_message(prompt):\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "          {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use. Remember, you are not generating the system message for data generation -- you are generating the system message to use for inference. A good format to follow is `Given $INPUT_DATA, you will $WHAT_THE_MODEL_SHOULD_DO.`.\\n\\nMake it as concise as possible. Include nothing but the system prompt in your response.\\n\\nFor example, never write: `\\\"$SYSTEM_PROMPT_HERE\\\"`.\\n\\nIt should be like: `$SYSTEM_PROMPT_HERE`.\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt.strip(),\n",
        "          }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=500,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "system_message = generate_system_message(prompt)\n",
        "\n",
        "print(f'The system message is: `{system_message}`. Feel free to re-run this cell if you want a better result.')"
      ],
      "metadata": {
        "id": "xMcfhW6Guh2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bae2d61-3798-4753-df26-f3e7dbe6f5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The system message is: `Given your prompt, the model will generate a response in both English and Spanish.`. Feel free to re-run this cell if you want a better result.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's put our examples into a dataframe and turn them into a final pair of datasets."
      ],
      "metadata": {
        "id": "G6BqZ-hjseBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to store prompts and responses\n",
        "prompts = []\n",
        "responses = []\n",
        "\n",
        "# Parse out prompts and responses from examples\n",
        "for example in prev_examples:\n",
        "  try:\n",
        "    split_example = example.split('-----------')\n",
        "    prompts.append(split_example[1].strip())\n",
        "    responses.append(split_example[3].strip())\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'prompt': prompts,\n",
        "    'response': responses\n",
        "})\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print('There are ' + str(len(df)) + ' successfully-generated examples.')\n",
        "\n",
        "# Initialize list to store training examples\n",
        "training_examples = []\n",
        "\n",
        "# Create training examples in the format required for GPT fine-tuning\n",
        "for index, row in df.iterrows():\n",
        "    training_example = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_message.strip()},\n",
        "            {\"role\": \"user\", \"content\": row['prompt']},\n",
        "            {\"role\": \"assistant\", \"content\": row['response']}\n",
        "        ]\n",
        "    }\n",
        "    training_examples.append(training_example)\n",
        "\n",
        "# Save training examples to a .jsonl file\n",
        "with open('training_examples.jsonl', 'w') as f:\n",
        "    for example in training_examples:\n",
        "        f.write(json.dumps(example) + '\\n')"
      ],
      "metadata": {
        "id": "7CEdkYeRsdmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f55b1a-72fc-4d60-97ab-a8d9b3d9b874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 43 successfully-generated examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the file to OpenAI"
      ],
      "metadata": {
        "id": "KWTY6qVgXD_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = openai.files.create(\n",
        "  file=open(\"/content/training_examples.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ").id"
      ],
      "metadata": {
        "id": "4LjEUrI9XDgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model! You may need to wait a few minutes before running the next cell to allow for the file to process on OpenAI's servers."
      ],
      "metadata": {
        "id": "HmYRIq8dW9IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai migrate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2K-9vtJBlUY",
        "outputId": "e7992ecd-1f94-49b5-eb69-941c8c866958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⠁\u001b[1m\u001b[2m\u001b[0m \u001b[1m\u001b[2mFinding files                                                                 \u001b[0m\u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\n",
            "⠁\u001b[1m\u001b[2m\u001b[0m \u001b[1m\u001b[2mFinding files                                                                 \u001b[0m\u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2mFinding files                                                         \u001b[0m\n",
            "████████████████████████████████████████████████████████████████████████████ 0/0\u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2AProcessed 0 files and found 0 matches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job = openai.fine_tuning.jobs.create(training_file=file_id, model=\"gpt-4o-2024-08-06\")\n",
        "\n",
        "job_id = job.id"
      ],
      "metadata": {
        "id": "rdEyXmkoW80I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, just wait until the fine-tuning run is done, and you'll have a ready-to-use model!\n",
        "\n",
        "Run this cell every 20 minutes or so -- eventually, you'll see a message \"New fine-tuned model created\"\n",
        "\n",
        "Once you see that message, you can go to the OpenAI Playground (or keep going to the next cells and use the API) to try the model!"
      ],
      "metadata": {
        "id": "XUSX5QzmZMTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.fine_tuning.jobs.list_events(fine_tuning_job_id = job_id)"
      ],
      "metadata": {
        "id": "45DJZ7hHaBx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b485fe1a-15a6-4bbe-da90-866608394de1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-YecrXUddcoWpmxDfJ4zE3Fzj', created_at=1725135115, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-1acJCByflcnX3FqjiUQuMV2b', created_at=1725135108, level='info', message='Usage policy evaluations completed, model is now enabled for sampling', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-ukli2PIOnJH4vmwEGp4PcQXL', created_at=1725134955, level='info', message='Evaluating model against our usage policies before enabling', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-Oc3oR9jqYZdbpuAFBC6rrQo7', created_at=1725134955, level='info', message='New fine-tuned model created', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-wEZLUtLaVHufddOeHOp2oIA7', created_at=1725134954, level='info', message='Checkpoint created at step 86', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-JmkDczFdgk69yxKeEw0hRTAC', created_at=1725134954, level='info', message='Checkpoint created at step 43', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-TbzLPr9Rqr8HhXZgGs03QNFs', created_at=1725134942, level='info', message='Step 129/129: training loss=0.00', object='fine_tuning.job.event', data={'step': 129, 'train_loss': 0.002541000721976161, 'total_steps': 129, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-2S9WyWiAmkP8YVuuzjEIYSQd', created_at=1725134928, level='info', message='Step 128/129: training loss=0.12', object='fine_tuning.job.event', data={'step': 128, 'train_loss': 0.12191754579544067, 'total_steps': 129, 'train_mean_token_accuracy': 0.9368420839309692}, type='metrics'), FineTuningJobEvent(id='ftevent-iHVjjZpPu9z1Mhma32AQMTnR', created_at=1725134928, level='info', message='Step 127/129: training loss=0.20', object='fine_tuning.job.event', data={'step': 127, 'train_loss': 0.19820795953273773, 'total_steps': 129, 'train_mean_token_accuracy': 0.9220778942108154}, type='metrics'), FineTuningJobEvent(id='ftevent-RkCnLcevpdvfisa3ukeUJzsD', created_at=1725134926, level='info', message='Step 126/129: training loss=0.17', object='fine_tuning.job.event', data={'step': 126, 'train_loss': 0.17260339856147766, 'total_steps': 129, 'train_mean_token_accuracy': 0.9863013625144958}, type='metrics'), FineTuningJobEvent(id='ftevent-xAo19boIEpKSVNKisboatLLH', created_at=1725134924, level='info', message='Step 125/129: training loss=0.28', object='fine_tuning.job.event', data={'step': 125, 'train_loss': 0.28411415219306946, 'total_steps': 129, 'train_mean_token_accuracy': 0.9024389982223511}, type='metrics'), FineTuningJobEvent(id='ftevent-dlUQG8AnAtZz74aydDOIy9fQ', created_at=1725134922, level='info', message='Step 124/129: training loss=0.16', object='fine_tuning.job.event', data={'step': 124, 'train_loss': 0.1625688523054123, 'total_steps': 129, 'train_mean_token_accuracy': 0.9558823704719543}, type='metrics'), FineTuningJobEvent(id='ftevent-QRXoqkSOMji2dtjdoqBeikp9', created_at=1725134922, level='info', message='Step 123/129: training loss=0.22', object='fine_tuning.job.event', data={'step': 123, 'train_loss': 0.21669244766235352, 'total_steps': 129, 'train_mean_token_accuracy': 0.9166666865348816}, type='metrics'), FineTuningJobEvent(id='ftevent-7bDHQ3CgYeiFWRDulyNZJRay', created_at=1725134920, level='info', message='Step 122/129: training loss=0.06', object='fine_tuning.job.event', data={'step': 122, 'train_loss': 0.06030025705695152, 'total_steps': 129, 'train_mean_token_accuracy': 0.978723406791687}, type='metrics'), FineTuningJobEvent(id='ftevent-9z6tbPM1Lxcv7Z8A5iyF0n4P', created_at=1725134918, level='info', message='Step 121/129: training loss=0.00', object='fine_tuning.job.event', data={'step': 121, 'train_loss': 2.8946820748387836e-05, 'total_steps': 129, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-KfjPHKIxgHYkga2VtTmBHlTQ', created_at=1725134916, level='info', message='Step 120/129: training loss=0.03', object='fine_tuning.job.event', data={'step': 120, 'train_loss': 0.027514666318893433, 'total_steps': 129, 'train_mean_token_accuracy': 0.9904761910438538}, type='metrics'), FineTuningJobEvent(id='ftevent-McYU66vO1P5WMAjozdNwXHdj', created_at=1725134916, level='info', message='Step 119/129: training loss=0.11', object='fine_tuning.job.event', data={'step': 119, 'train_loss': 0.11290920525789261, 'total_steps': 129, 'train_mean_token_accuracy': 0.9857142567634583}, type='metrics'), FineTuningJobEvent(id='ftevent-Lxw9sjfhX0a7lgHKxYhQqS1B', created_at=1725134914, level='info', message='Step 118/129: training loss=0.00', object='fine_tuning.job.event', data={'step': 118, 'train_loss': 9.200151907862164e-06, 'total_steps': 129, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-3W1AreolUk3o9aIdP1KfzZpj', created_at=1725134912, level='info', message='Step 117/129: training loss=0.01', object='fine_tuning.job.event', data={'step': 117, 'train_loss': 0.011051975190639496, 'total_steps': 129, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-EirbTUqug7CWnJzgKdvJHvdz', created_at=1725134910, level='info', message='Step 116/129: training loss=0.03', object='fine_tuning.job.event', data={'step': 116, 'train_loss': 0.0345807820558548, 'total_steps': 129, 'train_mean_token_accuracy': 0.9868420958518982}, type='metrics')], object='list', has_more=True)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Once your model is trained, run the next cell to grab the fine-tuned model name."
      ],
      "metadata": {
        "id": "91ihW2O27Phl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_pre_object = openai.fine_tuning.jobs.retrieve(fine_tuning_job_id = job_id)\n",
        "model_name = model_name_pre_object.fine_tuned_model\n",
        "print(model_name)"
      ],
      "metadata": {
        "id": "eWBRBPh8aEzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255d6151-9cf2-4538-d68d-6e3a001fd773"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ft:gpt-4o-2024-08-06:personal::A2OhG3Mj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's try it out!"
      ],
      "metadata": {
        "id": "2OmZLoBX7oQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message,\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"Tell me some fun facts\",\n",
        "      }\n",
        "    ],\n",
        ")\n",
        "\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "uxbrmzc5dMuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "db5ac1dc-8f7c-4f13-a9b6-ebe382c5f6b7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! Here are some fun facts: / ¡Claro! Aquí tienes algunos datos curiosos:\\n\\n1. Honey never spoils. Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old and still good to eat. / La miel nunca se echa a perder. Los arqueólogos han encontrado recipientes de miel en tumbas egipcias que tienen más de 3000 años y aún son comestibles.\\n\\n2. The heart of a shrimp is located in its head. / El corazón de un camarón se encuentra en su cabeza.\\n\\n3. A group of flamingos is called a \"flamboyance.\" / Un grupo de flamencos se llama \"flamboyance\".\\n\\n4. Bananas are berries, but strawberries are not. / Las bananas son bayas, pero las fresas no lo son.\\n\\n5. A cow-bison hybrid is called a \"beefalo.\" / Un híbrido de vaca y bisonte se llama \"beefalo\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
